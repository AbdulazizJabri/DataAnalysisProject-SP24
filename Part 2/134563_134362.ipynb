{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COMP3602: Data Analysis and Visualization with Python, Spring 2024\n",
    "\n",
    "# Project Part 2\n",
    "\n",
    "Source URL of Dataset: [https://www.kaggle.com/datasets/teamincribo/cyber-security-attacks](https://www.kaggle.com/datasets/teamincribo/cyber-security-attacks)\n",
    "\n",
    "**Group Members:**\n",
    "\n",
    "- Abdulaziz Saud Al Jabri (134563)\n",
    "\n",
    "- Mazin Humood Al Dhuhli (134362)\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preprocessing is\n",
    "a crucial step in any data analysis or machine learning project. It\n",
    "involves cleaning, transforming, and organizing raw data into a\n",
    "format that is suitable for analysis. This step is essential because\n",
    "the quality of the data used for analysis directly affects the\n",
    "accuracy of the results obtained.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('cybersecurity_attacks.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "1. Fill in **missing values** in each feature (if it has) by using the mean value of that feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code borrowed from https://www.geeksforgeeks.org/pandas-filling-nan-in-categorical-data/\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df_clean = df.apply(lambda x: x.fillna(x.value_counts().index[0]))\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "2. Use **Box plots** to identify which features have\n",
    "outliers and replace these values with the mean value. For\n",
    "a supervised dataset, where the class labels are known,\n",
    "this mean value should be computed using only the values\n",
    "that belong to the same class. On the other hand, for\n",
    "unsupervised datasets where class labels are not available,\n",
    "this mean value should be computed using all the values in\n",
    "the feature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "data.boxplot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "3. Use **LabelEncoder** for the features which have\n",
    "categorical data to convert it into numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "data['Timestamp'] = labelencoder.fit_transform(data['Timestamp'])\n",
    "data['Source IP Address'] = labelencoder.fit_transform(data['Source IP Address'])\n",
    "data['Destination IP Address'] = labelencoder.fit_transform(data['Destination IP Address'])\n",
    "data['Protocol'] = labelencoder.fit_transform(data['Protocol'])\n",
    "data['Packet Type'] = labelencoder.fit_transform(data['Packet Type'])\n",
    "data['Traffic Type'] = labelencoder.fit_transform(data['Traffic Type'])\n",
    "data['Payload Data'] = labelencoder.fit_transform(data['Payload Data'])\n",
    "data['Malware Indicators'] = labelencoder.fit_transform(data['Malware Indicators'])\n",
    "data['Alerts/Warnings'] = labelencoder.fit_transform(data['Alerts/Warnings'])\n",
    "data['Attack Type'] = labelencoder.fit_transform(data['Attack Type'])\n",
    "data['Attack Signature'] = labelencoder.fit_transform(data['Attack Signature'])\n",
    "data['Action Taken'] = labelencoder.fit_transform(data['Action Taken'])\n",
    "data['Severity Level'] = labelencoder.fit_transform(data['Severity Level'])\n",
    "data['User Information'] = labelencoder.fit_transform(data['User Information'])\n",
    "data['Network Segment'] = labelencoder.fit_transform(data['Network Segment'])\n",
    "data['Geo-location Data'] = labelencoder.fit_transform(data['Geo-location Data'])\n",
    "data['Proxy Information'] = labelencoder.fit_transform(data['Proxy Information'])\n",
    "data['Firewall Logs'] = labelencoder.fit_transform(data['Firewall Logs'])\n",
    "data['IDS/IPS Alerts'] = labelencoder.fit_transform(data['IDS/IPS Alerts'])\n",
    "data['Log Source'] = labelencoder.fit_transform(data['Log Source'])\n",
    "data['Device Information'] = labelencoder.fit_transform(data['Device Information'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "4. Apply **Min-Max Normalization** on each feature to\n",
    "scale the values in the range [0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "data = pd.DataFrame(scaler.fit_transform(data), columns=data.columns)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "5. Analyze the dataset as its in long (tidy) or wide\n",
    "format. If it is already in long format, then **convert it** (by\n",
    "selecting 2 or more variables) to **wide** and visa-versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_columns = data.columns[1:]\n",
    "melted_data = data.melt(id_vars=['Timestamp'], value_vars=other_columns)\n",
    "melted_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "6. For unsupervised dataset (if you selected),\n",
    "**implement covariance-based method** to identify irrelevant\n",
    "features without using any libraries to compute the\n",
    "correlation coefficient. Utilize a heatmap to visualize the\n",
    "correlations and provide a list of the identified irrelevant\n",
    "features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "7. For supervised dataset (if you selected),\n",
    "**implement ANOVA method** to identify irrelevant features\n",
    "without using any libraries to compute the F-statistics.\n",
    "Utilize a bar chart to visualize the computed F- statistics\n",
    "and provide a list of the identified irrelevant features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> Our dataset is an unsuperivsed dataset. So, step 7 will not be implemented."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
